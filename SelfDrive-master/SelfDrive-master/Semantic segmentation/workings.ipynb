{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<carla.libcarla.World at 0x211b2f385e0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this was to try to set up traffic before taking images - not working - cars not moving in autopilot\n",
    "# adding traffic of X cars to the town\n",
    "#setting all cars on autopilit\n",
    "#spawning a ghero hehicle and attaching camrea to it\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "try:\n",
    "    sys.path.append(glob.glob('../carla/dist/carla-*%d.%d-%s.egg' % (\n",
    "        sys.version_info.major,\n",
    "        sys.version_info.minor,\n",
    "        'win-amd64' if os.name == 'nt' else 'linux-x86_64'))[0])\n",
    "except IndexError:\n",
    "    pass\n",
    "import time\n",
    "import carla #the sim library itself\n",
    "import random #to pick random spawn point\n",
    "import cv2 #to work with images from cameras\n",
    "import numpy as np #in this example to change image representation - re-shaping\n",
    "# connect to the sim \n",
    "client = carla.Client('localhost', 2000)\n",
    "client.set_timeout(60)\n",
    "\n",
    "#optional\n",
    "client.load_world('Town03')\n",
    "# time.sleep(5)\n",
    "# world = client.get_world()\n",
    "# traffic_manager = client.get_trafficmanager(8000)\n",
    "# tm_port = traffic_manager.get_port()\n",
    "#settings = world.get_settings()\n",
    "#settings.synchronous_mode = True\n",
    "#settings.fixed_delta_seconds = 0.1\n",
    "#settings.no_rendering_mode = False\n",
    "# traffic_manager.set_synchronous_mode(True)\n",
    "# traffic_manager.global_percentage_speed_difference(70)\n",
    "#world.apply_settings(settings)\n",
    "# time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#world.apply_settings(settings)\n",
    "\n",
    "for actor in world.get_actors().filter('*vehicle*'):\n",
    "    actor.destroy()\n",
    "for sensor in world.get_actors().filter('*sensor*'):\n",
    "    sensor.destroy()\n",
    "\n",
    "x = 10\n",
    "\n",
    "vehicle_blueprints = world.get_blueprint_library().filter('*vehicle*')\n",
    "spawn_points = world.get_map().get_spawn_points()\n",
    "for i in range(0,x):\n",
    "    world.try_spawn_actor(random.choice(vehicle_blueprints), random.choice(spawn_points))\n",
    "time.sleep(2)\n",
    "\n",
    "vehicle_list = world.get_actors().filter('*vehicle*')\n",
    "for v in vehicle_list:\n",
    "     v.set_autopilot(True,tm_port)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_bp = world.get_blueprint_library().filter('*model3*')\n",
    "\n",
    "vehicle= None\n",
    "while vehicle is None:\n",
    "    vehicle = world.try_spawn_actor(vehicle_bp[0], random.choice(spawn_points))\n",
    "    time.sleep(2)\n",
    "vehicle.set_autopilot(True)\n",
    "\n",
    "#Tesla m3 camera setup aligned to real footage \n",
    "\n",
    "CAMERA_POS_Z = 1.3 \n",
    "CAMERA_POS_X = 1.4 \n",
    "\n",
    "camera_bp = world.get_blueprint_library().find('sensor.camera.rgb')\n",
    "camera_bp.set_attribute('image_size_x', '640') # this ratio works in CARLA 9.14 on Windows\n",
    "camera_bp.set_attribute('image_size_y', '480')\n",
    "camera_bp.set_attribute('fov', '90')\n",
    "\n",
    "camera_init_trans = carla.Transform(carla.Location(z=CAMERA_POS_Z,x=CAMERA_POS_X))\n",
    "#this creates the camera in the sim\n",
    "camera = world.spawn_actor(camera_bp,camera_init_trans,attach_to=vehicle)\n",
    "\n",
    "def camera_callback(image,data_dict):\n",
    "    data_dict['image'] = np.reshape(np.copy(image.raw_data),(image.height,image.width,4))\n",
    "\n",
    "image_w = camera_bp.get_attribute('image_size_x').as_int()\n",
    "image_h = camera_bp.get_attribute('image_size_y').as_int()\n",
    "\n",
    "camera_data = {'image': np.zeros((image_h,image_w,4))}\n",
    "# this actually opens a live stream from the camera\n",
    "camera.listen(lambda image: camera_callback(image,camera_data))\n",
    "\n",
    "# display the camera\n",
    "while True:\n",
    "      \n",
    "    # Dispaly with imshow\n",
    "    cv2.imshow('All cameras',camera_data['image'])\n",
    "    \n",
    "    # Break loop if user presses q\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "camera.stop() # this is the opposite of camera.listen\n",
    "for actor in world.get_actors().filter('*vehicle*'):\n",
    "    actor.destroy()\n",
    "for sensor in world.get_actors().filter('*sensor*'):\n",
    "    sensor.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "world = client.get_world()\n",
    "spawn_points = world.get_map().get_spawn_points()\n",
    "start_point = spawn_points[0]\n",
    "spectator = world.get_spectator()\n",
    "spectator.set_transform(start_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<carla.libcarla.World at 0x266db7f2a40>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.load_world('Town03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get colour from where mouse is - ChatGPT\n",
    "import cv2\n",
    "\n",
    "# Function to get RGB values at a specific point\n",
    "def get_rgb_values(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDBLCLK:\n",
    "        # Get the RGB values at the clicked point\n",
    "        b, g, r = img[y, x]\n",
    "        print(f\"RGB values at ({x}, {y}): R={r}, G={g}, B={b}\")\n",
    "\n",
    "# Load an image using OpenCV\n",
    "img = cv2.imread('C:/SelfDrive/Semantic segmentation/out_sem/sem/1702966369463358200.png')  # Replace 'your_image_path.jpg' with the path to your image\n",
    "\n",
    "# Create a window and set the mouse callback function\n",
    "cv2.namedWindow('image')\n",
    "cv2.setMouseCallback('image', get_rgb_values)\n",
    "\n",
    "while True:\n",
    "    cv2.imshow('image', img)\n",
    "\n",
    "    # Press 'q' to exit the loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sb3_15",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
