{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original lane mask prediction\n",
    "# try weighted model\n",
    "# Lane marking only\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"   # trying disabling GPU\n",
    "\n",
    "import tensorflow as tf\n",
    "import segmentation_models as sm\n",
    "import time\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt \n",
    "from keras import backend as K\n",
    "\n",
    "BACKBONE = 'resnet34'\n",
    "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
    "\n",
    "SIZE_X = 640\n",
    "SIZE_Y = 480\n",
    "\n",
    "validation_portion = 0.2\n",
    "sample_size_limit = 10_000\n",
    "\n",
    "sem_path = 'c:/SelfDrive/Semantic Segmentation/out_sem/rgb'\n",
    "map_path = 'c:/SelfDrive/Semantic Segmentation/out_sem/map_ln'\n",
    "\n",
    "'''\n",
    "def class_weighted_cross_entropy_loss(y_true,y_pred):\n",
    "    class_weights = np.array([0.98,0.02])\n",
    "    cross_entropy_loss = tf.keras.losses.binary_crossentropy(y_true,y_pred,from_logits=False)\n",
    "    class_weights = tf.cast(tf.reshape(class_weights,[1,-1]), tf.float32)\n",
    "    tf.cast(cross_entropy_loss, tf.float32)\n",
    "    weighterd_cross_entropy_loss = tf.reduce_mean(cross_entropy_loss * class_weights)\n",
    "    return weighterd_cross_entropy_loss\n",
    "'''\n",
    "\n",
    "def weighted_binary_crossentropy( y_true, y_pred, weight=1. ) :\n",
    "    y_true = K.clip(y_true, K.epsilon(), 1-K.epsilon())\n",
    "    y_pred = K.clip(y_pred, K.epsilon(), 1-K.epsilon())\n",
    "    logloss = -(y_true * K.log(y_pred) * weight + (1 - y_true) * K.log(1 - y_pred))\n",
    "    return K.mean( logloss, axis=-1)\n",
    "\n",
    "sem_images = os.listdir(sem_path)\n",
    "random.shuffle(sem_images)\n",
    "\n",
    "#reduce number of images here\n",
    "sem_images = sem_images[0:sample_size_limit]\n",
    "\n",
    "img_count = len(sem_images)\n",
    "\n",
    "train_len = int(img_count * (1-validation_portion))\n",
    "val_len = img_count - train_len\n",
    "\n",
    "x_train = np.zeros(shape=(train_len,SIZE_Y,SIZE_X,3),dtype=np.float16)\n",
    "x_val = np.zeros(shape=(val_len,SIZE_Y,SIZE_X,3),dtype=np.float16)\n",
    "\n",
    "y_train =  np.zeros(shape=(train_len,SIZE_Y,SIZE_X),dtype=np.float16)\n",
    "y_val =  np.zeros(shape=(val_len,SIZE_Y,SIZE_X),dtype=np.float16)\n",
    "\n",
    "i = 0\n",
    "i_val = 0\n",
    "for file in sem_images:\n",
    "        pth = os.path.join(sem_path,file) \n",
    "        img = cv2.imread(pth,cv2.IMREAD_COLOR)\n",
    "        pth = os.path.join(map_path,file) \n",
    "        map = cv2.imread(pth,0)\n",
    "        \n",
    "        if i < train_len:\n",
    "            x_train[i] = img/255\n",
    "            y_train[i] = map/255\n",
    "        else:\n",
    "            x_val[i_val] = img/255\n",
    "            y_val[i_val] = map/255\n",
    "            i_val += 1\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "x_train = preprocess_input(x_train)\n",
    "x_val = preprocess_input(x_val)\n",
    "\n",
    "# run without GPU\n",
    "NAME = \"UNET_LANES_WCE_LOSS-{}\".format(int(time.time()))\n",
    "#tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))\n",
    "model = sm.Unet(BACKBONE, encoder_weights='imagenet')\n",
    "model.compile(optimizer='adam',loss=weighted_binary_crossentropy,metrics=['mse'])\n",
    "#model.summary()\n",
    "\n",
    "\n",
    "history = model.fit(x_train,y_train,batch_size=16,epochs=20,verbose=1,validation_data=(x_val,y_val))\n",
    "model.save('model/{}'.format(NAME),save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing cropping \n",
    "import os\n",
    "import cv2\n",
    "\n",
    "BOTTOM_CROP = 0.55 #take bottom share oh sem image\n",
    "sem_path = 'c:/SelfDrive/Map Projection/img'\n",
    "sem_images = os.listdir(sem_path)\n",
    "\n",
    "# get sizing\n",
    "test_file = sem_images[0]\n",
    "test_img = cv2.imread(os.path.join(sem_path,test_file),cv2.IMREAD_COLOR)\n",
    "SIZE_Y = test_img.shape[0]\n",
    "SIZE_X = test_img.shape[1]\n",
    "\n",
    "cropped_img = test_img[int(SIZE_Y*(1-BOTTOM_CROP)):,:,:]\n",
    "#re-define height after cropping\n",
    "SIZE_Y = cropped_img.shape[0]\n",
    "cv2.imshow(\"test\", cropped_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 265, 640, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 265, 640, 64)      1792      \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 132, 320, 64)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 132, 320, 128)     73856     \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 66, 160, 128)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 66, 160, 256)      295168    \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 33, 80, 256)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 33, 80, 256)       0         \n",
      "                                                                 \n",
      " up_sampling2d_9 (UpSampling  (None, 66, 160, 256)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 66, 160, 128)      295040    \n",
      "                                                                 \n",
      " up_sampling2d_10 (UpSamplin  (None, 132, 320, 128)    0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 132, 320, 64)      73792     \n",
      "                                                                 \n",
      " up_sampling2d_11 (UpSamplin  (None, 264, 640, 64)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 264, 640, 32)      18464     \n",
      "                                                                 \n",
      " resizing_1 (Resizing)       (None, 264, 240, 32)      0         \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 264, 240, 3)       867       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 758,979\n",
      "Trainable params: 758,979\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[(None, 265, 640, 3)]\n",
      "(None, 265, 640, 64)\n",
      "(None, 132, 320, 64)\n",
      "(None, 132, 320, 128)\n",
      "(None, 66, 160, 128)\n",
      "(None, 66, 160, 256)\n",
      "(None, 33, 80, 256)\n",
      "(None, 33, 80, 256)\n",
      "(None, 66, 160, 256)\n",
      "(None, 66, 160, 128)\n",
      "(None, 132, 320, 128)\n",
      "(None, 132, 320, 64)\n",
      "(None, 264, 640, 64)\n",
      "(None, 264, 640, 32)\n",
      "(None, 264, 240, 32)\n",
      "(None, 264, 240, 3)\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'mean_squared_error/SquaredDifference' defined at (most recent call last):\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\traitlets\\config\\application.py\", line 1041, in launch_instance\n      app.start()\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\asyncio\\base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\asyncio\\base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\asyncio\\events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 387, in do_execute\n      cell_id=cell_id,\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2976, in run_cell\n      raw_cell, store_history, silent, shell_futures, cell_id\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3030, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3258, in run_cell_async\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3473, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3553, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Vadim\\AppData\\Local\\Temp\\ipykernel_9100\\1776728459.py\", line 147, in <module>\n      validation_data=val_generator, validation_steps=len(val_files) // BATCH_SIZE)\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py\", line 1053, in compute_loss\n      y, y_pred, sample_weight, regularization_losses=self.losses\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\keras\\losses.py\", line 272, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\keras\\losses.py\", line 1486, in mean_squared_error\n      return backend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)\nNode: 'mean_squared_error/SquaredDifference'\nrequired broadcastable shapes\n\t [[{{node mean_squared_error/SquaredDifference}}]] [Op:__inference_train_function_4997]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9100\\1776728459.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[1;31m# Train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m history = model.fit(train_generator, steps_per_epoch=len(train_files) // BATCH_SIZE, epochs=15,\n\u001b[1;32m--> 147\u001b[1;33m           validation_data=val_generator, validation_steps=len(val_files) // BATCH_SIZE)\n\u001b[0m\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 55\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'mean_squared_error/SquaredDifference' defined at (most recent call last):\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\traitlets\\config\\application.py\", line 1041, in launch_instance\n      app.start()\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\asyncio\\base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\asyncio\\base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\asyncio\\events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 387, in do_execute\n      cell_id=cell_id,\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2976, in run_cell\n      raw_cell, store_history, silent, shell_futures, cell_id\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3030, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3258, in run_cell_async\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3473, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3553, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Vadim\\AppData\\Local\\Temp\\ipykernel_9100\\1776728459.py\", line 147, in <module>\n      validation_data=val_generator, validation_steps=len(val_files) // BATCH_SIZE)\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py\", line 1053, in compute_loss\n      y, y_pred, sample_weight, regularization_losses=self.losses\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\keras\\losses.py\", line 272, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\Vadim\\.conda\\envs\\tf2\\lib\\site-packages\\keras\\losses.py\", line 1486, in mean_squared_error\n      return backend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)\nNode: 'mean_squared_error/SquaredDifference'\nrequired broadcastable shapes\n\t [[{{node mean_squared_error/SquaredDifference}}]] [Op:__inference_train_function_4997]"
     ]
    }
   ],
   "source": [
    "# changing original model\n",
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"   # trying disabling GPU\n",
    "\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import cv2\n",
    "import random\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt \n",
    "from keras import backend as K\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Input, Resizing, UpSampling2D, Dropout, MaxPooling2D, Conv2D, Conv2DTranspose, Concatenate, Embedding, Reshape, Flatten, Activation, BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from keras import regularizers\n",
    "\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "#SIZE_X = 640\n",
    "#SIZE_Y = 480\n",
    "BOTTOM_CROP = 0.55 #take bottom share oh sem image\n",
    "\n",
    "validation_portion = 0.2\n",
    "sample_size_limit = 10_000\n",
    "\n",
    "sem_path = 'c:/SelfDrive/Map Projection/img'\n",
    "map_path = 'c:/SelfDrive/Map Projection/map_clean'\n",
    "\n",
    "def weighted_binary_crossentropy( y_true, y_pred, weight=1. ) :\n",
    "    y_true = K.clip(y_true, K.epsilon(), 1-K.epsilon())\n",
    "    y_pred = K.clip(y_pred, K.epsilon(), 1-K.epsilon())\n",
    "    logloss = -(y_true * K.log(y_pred) * weight + (1 - y_true) * K.log(1 - y_pred))\n",
    "    return K.mean( logloss, axis=-1)\n",
    "\n",
    "# old sem_images = os.listdir(sem_path)\n",
    "sem_images = [os.path.join(sem_path, file) for file in os.listdir(sem_path) if file.endswith('.png')]\n",
    "map_images = [os.path.join(map_path, file) for file in os.listdir(map_path) if file.endswith('.png')]\n",
    "random.shuffle(sem_images)\n",
    "\n",
    "# get sizing\n",
    "test_file = sem_images[0]\n",
    "test_img = cv2.imread(test_file,cv2.IMREAD_COLOR)\n",
    "size_y = test_img.shape[0]\n",
    "size_x = test_img.shape[1]\n",
    "\n",
    "cropped_img = test_img[int(size_y*(1-BOTTOM_CROP)):,:,:]\n",
    "#re-define height after cropping\n",
    "size_y = cropped_img.shape[0]\n",
    "\n",
    "test_file = map_images[0]\n",
    "test_map = cv2.imread(test_file,cv2.IMREAD_COLOR)\n",
    "size_y_map = test_map.shape[0]\n",
    "size_x_map = test_map.shape[1]\n",
    "\n",
    "\n",
    "# Create a custom data generator\n",
    "def custom_data_generator(image_files, batch_size):\n",
    "    num_samples = len(image_files)\n",
    "    while True:\n",
    "        indices = np.random.randint(0, num_samples, batch_size)\n",
    "        batch_images = []\n",
    "        batch_maps = []\n",
    "        for idx in indices:\n",
    "            image_path = image_files[idx]\n",
    "            map_p = os.path.join(map_path,os.path.basename(image_path))\n",
    "            image = preprocess_image(image_path)\n",
    "            map_img = preprocess_map(map_p)\n",
    "            batch_images.append(image)\n",
    "            batch_maps.append(map_img)\n",
    "        yield [np.array(batch_images),batch_maps]\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = keras.preprocessing.image.load_img(image_path, target_size=(size_x,size_y)) #where image_size = (WIDTH,HEIGHT)\n",
    "    image = keras.preprocessing.image.img_to_array(image)\n",
    "    #bottom only part of image if it is a semantic or RGB image\n",
    "    image = image[int(image.shape[0]*(1-BOTTOM_CROP)):,:,:]\n",
    "    image = image / 255.0  # Normalize pixel values between 0 and 1\n",
    "    return image\n",
    "\n",
    "def preprocess_map(map_pth):\n",
    "    map_im = keras.preprocessing.image.load_img(map_pth, target_size=(size_x_map,size_y_map)) #where image_size = (WIDTH,HEIGHT)\n",
    "    map_im = keras.preprocessing.image.img_to_array(map_im)\n",
    "    map_im = map_im / 255.0  # Normalize pixel values between 0 and 1\n",
    "    return map_im\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    # Image input\n",
    "    output_shape = (size_y_map,size_x_map,3)\n",
    "    image_input = Input(shape=(size_y, size_x, 3))\n",
    "    # Preprocess the image input\n",
    "    x = Conv2D(64, kernel_size=(3, 3), activation='relu',padding='same')(image_input)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Conv2D(128, kernel_size=(3, 3), activation='relu',padding='same')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Conv2D(256, kernel_size=(3, 3), activation='relu',padding='same')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    #x = Dense(256, activation='relu',activity_regularizer=regularizers.L2(1e-5))(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same') (x)\n",
    "    x = Resizing(264,240) (x)\n",
    "    output = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "    #x = Dense(128, activation='relu',activity_regularizer=regularizers.L2(1e-5))(x)\n",
    "        # Dense layers for prediction\n",
    "    # Create the model\n",
    "    #x = Conv2DTranspose(3, (3, 3), strides=(8, 3), padding='same', activation='sigmoid')(x)\n",
    "    #output = Reshape(target_shape=(size_y_map, size_x_map, 3)) (x)\n",
    "    #model = Model(inputs=image_input, outputs=output)\n",
    "    \n",
    "    \n",
    "    model = Model(image_input, output)\n",
    "    model.build((None,) + output_shape)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "split_index = int(len(sem_images) * 0.8)  # 80% for training, 20% for validation\n",
    "train_files, val_files = sem_images[:split_index], sem_images[split_index:]\n",
    "\n",
    "# Create data generators for training and validation\n",
    "train_generator = custom_data_generator(train_files, BATCH_SIZE)\n",
    "val_generator = custom_data_generator(val_files, BATCH_SIZE)\n",
    "\n",
    "\n",
    "# run \n",
    "NAME = \"UNET_MAP_WCE_LOSS-{}\".format(int(time.time()))\n",
    "#tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))\n",
    "# need to build a new model\n",
    "\n",
    "model = create_model()\n",
    "model.compile(optimizer='adam',loss=weighted_binary_crossentropy,metrics=['mse'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "for layer in model.layers:\n",
    "    print(layer.output_shape)\n",
    "# Train the model\n",
    "history = model.fit(train_generator, steps_per_epoch=len(train_files) // BATCH_SIZE, epochs=15,\n",
    "          validation_data=val_generator, validation_steps=len(val_files) // BATCH_SIZE)\n",
    "\n",
    "\n",
    "model.save('model/{}'.format(NAME),save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(264, 240, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_map.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
